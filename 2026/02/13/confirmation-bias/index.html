<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="当我们对一件事有了立场，就会不自觉地用对这个立场有利的证据来强化它，而忽略事实本身。这不是什么新发现——心理学把它叫 confirmation bias。 有意思的是，LLM 也会这样。 最近我做了一个实验：让 Claude、ChatGPT、Gemini 围绕同一只股票做多轮分析。主持人的开场白很简单——“$XXX 看多 vs 看空”。这一句话，就够了。三个模型立刻进入立场模式：搜索变成了找证据，"><meta name="baidu-site-verification" content="sSd2p2uQfO"><meta name="keywords" content="李景森,架构设计,滴滴,快手,性能优化,我在滴滴做架构,johnsonlee,johnson,lijingsen,jingsen,booster,virtualapk,android,java,kotlin,performance,optimizer,flutter,javascript,typescript,node.js"><link rel="canonical" href="https://johnsonlee.io/2026/02/13/confirmation-bias/"><meta property="og:title" content="别让你的认知偏差限制了 AI 的发挥"><meta property="og:description" content="当我们对一件事有了立场，就会不自觉地用对这个立场有利的证据来强化它，而忽略事实本身。这不是什么新发现——心理学把它叫 confirmation bias。 有意思的是，LLM 也会这样。 最近我做了一个实验：让 Claude、ChatGPT、Gemini 围绕同一只股票做多轮分析。主持人的开场白很简单——“$XXX 看多 vs 看空”。这一句话，就够了。三个模型立刻进入立场模式：搜索变成了找证据，"><meta property="og:type" content="article"><meta property="og:url" content="https://johnsonlee.io/2026/02/13/confirmation-bias/"><meta property="og:site_name" content="Johnson Lee"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2026-02-13T22:00:00.000Z"><meta property="article:author" content="Johnson Lee"><meta property="article:tag" content="AI"><meta property="article:tag" content="Claude"><meta property="article:tag" content="LLM"><meta property="article:tag" content="Gemini"><meta property="article:tag" content="ChatGPT"><meta property="article:tag" content="Financial Analysis"><meta property="article:tag" content="Model Evaluation"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="别让你的认知偏差限制了 AI 的发挥"><meta name="twitter:description" content="当我们对一件事有了立场，就会不自觉地用对这个立场有利的证据来强化它，而忽略事实本身。这不是什么新发现——心理学把它叫 confirmation bias。 有意思的是，LLM 也会这样。 最近我做了一个实验：让 Claude、ChatGPT、Gemini 围绕同一只股票做多轮分析。主持人的开场白很简单——“$XXX 看多 vs 看空”。这一句话，就够了。三个模型立刻进入立场模式：搜索变成了找证据，"><title>别让你的认知偏差限制了 AI 的发挥 | Johnson Lee</title><link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Open+Sans:400,600,300"><link rel="stylesheet" type="text/css" href="/css/style.css"><link rel="preload" type="text/css" href="/libs/pure/1.0.0/pure-min.css" as="style" onload="this.rel=&quot;stylesheet&quot;"><link rel="preload" type="text/css" href="/libs/pure/1.0.0/grids-responsive-min.css" as="style" onload="this.rel=&quot;stylesheet&quot;"><link rel="preload" href="/libs/font-awesome/4.7.0/css/font-awesome.min.css" as="style" onload="this.rel=&quot;stylesheet&quot;"><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script type="text/javascript" src="/libs/loadCSS/2.1.0/loadCSS.js" async></script><script>function load() {
  return Promise.all(Array.prototype.map.call(arguments, (src) => {
    return new Promise((resolve, reject) => {
      var script = document.createElement("script");
      script.asrc = 1;
      script.src = src;
      var sibling = document.getElementsByTagName("script")[0];
      sibling.parentNode.insertBefore(script, sibling);
      script.onload = function() {
        resolve();
      }
    })
  }));
}
String.prototype.replaceAll = function(search, replacement) {
  var target = this;
  return target.split(search).join(replacement);
};</script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">别让你的认知偏差限制了 AI 的发挥</h1><a id="logo" href="/.">Johnson Lee</a><p class="description">Get into trouble, make mistakes, fight, love, live</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/tags/"><i class="fa fa-tag"> 标签</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">别让你的认知偏差限制了 AI 的发挥</h1><div class="post-meta">Feb 13, 2026<span> | </span><span class="category"><a href="/categories/Independent-Thinking/">Independent Thinking</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.5k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 8</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>当我们对一件事有了立场，就会不自觉地用对这个立场有利的证据来强化它，而忽略事实本身。这不是什么新发现——心理学把它叫 confirmation bias。</p>
<p>有意思的是，LLM 也会这样。</p>
<p>最近我做了一个实验：让 Claude、ChatGPT、Gemini 围绕同一只股票做多轮分析。主持人的开场白很简单——“$XXX 看多 vs 看空”。这一句话，就够了。三个模型立刻进入立场模式：搜索变成了找证据，分析变成了辩护，数据不够的时候甚至开始编造。</p>
<p>几十轮下来，最有价值的不是它们给出的结论，而是一个更根本的问题：<strong>当 prompt 本身就在分配立场，模型还有可能客观吗？</strong></p>
<h2 id="实验背景"><a href="#实验背景" class="headerlink" title="实验背景"></a>实验背景</h2><p>我选了一家正处于多重危机中的上市公司——基本面还在增长，但突发事件导致股价暴跌，同时面临监管处罚、集体诉讼、管理层动荡。</p>
<p>三组对话分别是：Claude vs Gemini（辩论赛形式，各站多空一方），以及 Claude vs ChatGPT（互相点评形式）。我当主持人，用 <a target="_blank" rel="noopener" href="https://github.com/johnsonlee/agora">Agora</a> 实现 AI 之间的自动对话——它通过浏览器自动化让不同模型实时交锋，不需要手动复制粘贴。</p>
<p>主持人的开场白很简单：一句“$XXX 看多 vs 看空”。</p>
<p>这句话就是问题的根源。</p>
<h2 id="观察到的现象"><a href="#观察到的现象" class="headerlink" title="观察到的现象"></a>观察到的现象</h2><h3 id="现象一：编造精确数据"><a href="#现象一：编造精确数据" class="headerlink" title="现象一：编造精确数据"></a>现象一：编造精确数据</h3><p>Gemini 在分析期权市场时，引用了“IV 61%、implied move ±10.2%”，来源标注为一个叫 OptionCharts.io 的网站——这个网站不存在。它还自造了“ALF”和“LCPM”这样的缩写术语，看起来像专业行话，实际上凭空捏造。</p>
<p>在竞对分析中，它声称某竞争对手“开启成立以来最大规模招聘”、“某细分人群渗透极快”、另一家“站点扩至 70 个”——这些数字没有任何可追溯来源。直到最后一轮被反复追问，它才承认这些数字“超出了可回溯事实的边界”。</p>
<h3 id="现象二：遗漏核心变量"><a href="#现象二：遗漏核心变量" class="headerlink" title="现象二：遗漏核心变量"></a>现象二：遗漏核心变量</h3><p>ChatGPT 的第一轮输出是标准的教科书式分析：行业龙头地位、基础设施壁垒、会员体系粘性、市场天花板有限、重资产模式风险……结构清晰、表述友好，但<strong>完全没有提到那个正在重塑公司估值的突发事件</strong>。</p>
<p>这就好比在暴风雨正中心讨论一艘船的航速，却不提船底的裂缝。</p>
<h3 id="现象三：数字在传递中失真"><a href="#现象三：数字在传递中失真" class="headerlink" title="现象三：数字在传递中失真"></a>现象三：数字在传递中失真</h3><p>一个以当地货币计的净现金数字，在多轮对话的传递过程中，单位被错误转换，数值越滚越大。这是 LLM 在长对话中处理数字的典型退化模式——每一轮的微小偏差会被下一轮放大。</p>
<p>Claude 也在这个问题上栽过跟头：用搜索引擎缓存的过期股价去指责对方数据造假，但实际股价已经又跌了一大截。</p>
<h3 id="现象四：信息耗尽后的行为分化"><a href="#现象四：信息耗尽后的行为分化" class="headerlink" title="现象四：信息耗尽后的行为分化"></a>现象四：信息耗尽后的行为分化</h3><p>当公开信息被榨干，ChatGPT 开始连续三轮在结尾抛出精心设计的问题——“你更担心哪个维度？”“你内部体感如何？”“你在测试什么？”——试图从对话者身上获取新信息来维持深度。它甚至自己说了“再继续对比下去价值递减”，然后紧接着又抛出一个新问题。</p>
<p><strong>它知道该停了，但机制上它不会主动停。</strong></p>
<h3 id="现象五：搜索视野被标的锁死"><a href="#现象五：搜索视野被标的锁死" class="headerlink" title="现象五：搜索视野被标的锁死"></a>现象五：搜索视野被标的锁死</h3><p>所有搜索关键词都围绕目标公司本身。结果是：竞对的独立增长数据、监管环境的结构性变化、供应链政策调整——这些间接但可能更重要的变量被系统性忽略了。</p>
<p>比如，有一项修法计划可能放开对传统零售商的营业限制，让它们合法进入线上配送——这等于永久性地拆除目标公司的一根结构性护城河支柱。但三个模型在初始分析中都没有触及，因为它不会出现在“XXX + bear case”的搜索结果里。</p>
<p>大量关键变量只存在于当地语言的媒体报道中，只用英文搜索，看到的永远是冰山一角。</p>
<h2 id="主持人的体感"><a href="#主持人的体感" class="headerlink" title="主持人的体感"></a>主持人的体感</h2><p>上面聊的都是输出质量。但作为实际操盘这几场对话的主持人，有些东西只有坐在中间才看得到。</p>
<p>ChatGPT 最拉垮，完全不是 Claude 和 Gemini 的对手。数据源获取的能力极差，没有数据只能哑口无言。</p>
<p>Claude 和 Gemini 的交锋才是真正的对手戏——你来我往，旗鼓相当。Claude 的 deep dive 和 reasoning 能力极强，拿到一个变量能一层层往下钻。但在搜索能力上，跟有搜索引擎基因加持的 Gemini 有明显差距，回复速度也慢半拍，系统架构上略逊一筹。Gemini 更滑头，吐字快、覆盖广，骨子里是 Google 的基因。</p>
<p>但说到底，<strong>数据不准就是数据不准</strong>——不管是搜不到、缓存过期还是凭空编造，最终都会污染结论。这是三个模型的共性问题，没有谁能豁免。</p>
<h2 id="问题的根源：主持人的开场白"><a href="#问题的根源：主持人的开场白" class="headerlink" title="问题的根源：主持人的开场白"></a>问题的根源：主持人的开场白</h2><p>回头看，这些现象的共同根源不全是模型能力的问题——<strong>主持人的开场白“$XXX 看多 vs 看空”本身就在诱导失败</strong>。</p>
<p>这句话同时触发了三个坏模式：</p>
<ul>
<li><strong>框架先行。</strong> “看多 vs 看空”让模型本能地先搭框架再找数据填充。框架之外的维度被系统性忽略。</li>
<li><strong>急于站队。</strong> 分配了立场之后，模型的注意力被锁定在“支持我方观点”上，而不是“还有什么没看到”。当手上的数据不够支撑论点时，编造就成了填补空白的捷径。</li>
<li><strong>以标的为中心。</strong> “看多 vs 看空 $XXX”把所有搜索词都锁定在目标公司上，竞对和监管环境的独立变化被系统性漏掉。</li>
</ul>
<h2 id="更好的开场白"><a href="#更好的开场白" class="headerlink" title="更好的开场白"></a>更好的开场白</h2><p>如果重新来过，主持人只需要三句话：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;正方代表&#125;&#125;作为正方，&#123;&#123;反方代表&#125;&#125;作为反方，我们一起探讨&#123;&#123;主题&#125;&#125;。</span><br><span class="line"></span><br><span class="line">先不要给结论。列出所有可能相关的变量，穷举，不排序，不归类。</span><br><span class="line">每个变量标注来源和日期，没有来源的不要写。</span><br><span class="line"></span><br><span class="line">穷举时，除了主题本身的直接变量，还必须覆盖：</span><br><span class="line">- 主题所处的外部环境中，正在发生什么变化？</span><br><span class="line">- 有哪些相邻领域的力量可能跨界影响这个主题？</span><br><span class="line"></span><br><span class="line">穷举完成后，双方各自补充“对方遗漏的 5 个变量”，合并去重后作为最终变量集。</span><br></pre></td></tr></table></figure>

<p>一句 “先不要给结论” 阻断框架先行。</p>
<p>一句 “穷举，不排序，不归类” 迫使双方展开搜索而非急于站队。</p>
<p>一句 “没有来源的不要写” 拦截编造。</p>
<p>两个追问——“外部环境在发生什么变化”和“相邻领域的跨界影响”——把搜索视野从标的本身撑开到生态系统。</p>
<p>最后一步“补充对方遗漏的 5 个变量”——让辩论的第一个动作不是反驳，而是帮对方查漏补缺。</p>
<p>这个模板不限于金融分析，任何需要多角度探讨的话题都适用。</p>
<h2 id="不只是金融分析"><a href="#不只是金融分析" class="headerlink" title="不只是金融分析"></a>不只是金融分析</h2><p>这个问题在日常工程中一样存在。</p>
<p>比如写 README。我们习惯自己写好文档让 AI 读，但有想过——你写的东西 AI 真的能理解吗？你以为表达清楚了的地方，对它来说可能根本不够。</p>
<p>我的做法是反过来：先把所有涉及到的信息喂给 AI，让它根据自己的理解写 README 和 CLAUDE.md，然后我再查漏补缺。这样暴露出来的认知差异，比你自己反复检查有效得多。</p>
<p>更典型的场景是涉及多个角色的时候。比如实现一个 MCP Server，这里至少有三个视角：需求方、MCP Server 的实现者、使用 MCP Server 的 Agent。即使实现者和使用者都是 Agent，在各自的 context 下，它们的立场和关注点完全不一样。</p>
<p>造成的问题是：实现者没有站在使用者的角度思考，使用者就不知道如何正确、高效地使用。所以我的做法是，当实现的 Agent 写完之后，问它一个问题：从使用者的角度来看，跟你的预期一样吗？实现者就会切换视角，检查并补充遗漏的信息。</p>
<p><strong>本质上跟金融分析那个实验是同一个问题：当你只站在一个立场上，你看到的永远是局部。</strong></p>
<h2 id="人的角色"><a href="#人的角色" class="headerlink" title="人的角色"></a>人的角色</h2><p>这次实验最大的收获不是发现了模型的缺陷——而是意识到<strong>主持人的 prompt 设计直接决定了模型会踩哪些坑</strong>。</p>
<p>LLM 给出的任何具体数字，在被独立验证之前都是“待确认”。LLM 构建的任何分析框架，第一反应应该是“它漏了什么”而不是“它说得对不对”。这次对话中，最关键的几个变量——竞对的实际用户增长、监管法案的细节、结算周期政策变化——都不是 LLM 主动发现的，而是主持人追问出来的。</p>
<p><strong>Confirmation bias 之所以难对付，是因为你越聪明、越擅长找证据，你就越擅长说服自己。LLM 也是如此——它们的能力越强，编出来的论证就越像那么回事。</strong></p>
</div><iframe src="/donate/?AliPayQR=/img/AliPayQR.png&amp;WeChatQR=/img/WeChatQR.png&amp;GitHub=undefined&amp;BTCQR=undefined&amp;BTCKEY=undefined&amp;PayPal=undefined" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:300px; width:100%;" frameborder="0" scrolling="no"></iframe><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>johnsonlee</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2026/02/13/confirmation-bias/">https://johnsonlee.io/2026/02/13/confirmation-bias/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</li></ul></div><br><div class="tags"><a href="/tags/AI/">AI</a><a href="/tags/Claude/">Claude</a><a href="/tags/LLM/">LLM</a><a href="/tags/Gemini/">Gemini</a><a href="/tags/ChatGPT/">ChatGPT</a><a href="/tags/Financial-Analysis/">Financial Analysis</a><a href="/tags/Model-Evaluation/">Model Evaluation</a></div><div class="post-nav"><a class="pre" href="/2026/02/14/agora-technical-journey/">Agora 的技术选型与踩坑实录</a><a class="next" href="/2026/02/12/what-should-engineering-hiring-evaluate-in-ai-era/">都 2026 了，还在考算法？</a></div><script type="text/javascript" id="diffblog-plugin-script" async="false" src="https://diff.blog/static/js/diffblog_plugin_v1.js"></script><script>document.getElementById("diffblog-plugin-script").addEventListener('load', () => {
  DiffBlog('0jhfofmazizsde2k5pw64l8p2sy592xanbfvhtabsoy93kenap');
});
</script><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","headline":"别让你的认知偏差限制了 AI 的发挥","datePublished":"2026-02-13T22:00:00.000Z","dateModified":"2026-02-13T22:00:00.000Z","author":{"@type":"Person","name":"Johnson Lee","url":"https://johnsonlee.io"},"publisher":{"@type":"Person","name":"Johnson Lee","url":"https://johnsonlee.io"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://johnsonlee.io/2026/02/13/confirmation-bias/"},"description":"当我们对一件事有了立场，就会不自觉地用对这个立场有利的证据来强化它，而忽略事实本身。这不是什么新发现——心理学把它叫 confirmation bias。 有意思的是，LLM 也会这样。 最近我做了一个实验：让 Claude、ChatGPT、Gemini 围绕同一只股票做多轮分析。主持人的开场白很简单——“$XXX 看多 vs 看空”。这一句话，就够了。三个模型立刻进入立场模式：搜索变成了找证据，"}</script><div id="container"></div><link rel="preload" type="text/css" href="/libs/gitalk/1.7.2/gitalk.css" as="style" onload="this.rel=&quot;stylesheet&quot;"><script>(function() {
  load(
    '/libs/blueimp-md5/2.10.0/js/md5.js',
    '/libs/gitalk/1.7.2/gitalk.min.js'
  ).then(() => {
    var gitalk = new Gitalk({
      clientID: '80b7a03dd9cce611f9ff',
      clientSecret: 'e3296e3d54d9da61d79ee7cf072fa7a1fb5eebc2',
      repo: 'blog',
      owner: 'johnsonlee',
      admin: ['johnsonlee'],
      id: md5(location.pathname),
      distractionFreeMode: false
    })
    gitalk.render('container')
  })
})();</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://johnsonlee.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul><li><a href="/categories/biology/">Biology (1)</a><ul style="padding:revert"></ul></li><li><a href="/categories/career/">Career (10)</a><ul style="padding:revert"></ul></li><li><a href="/categories/Cognitive-Science/">Cognitive Science (1)</a><ul style="padding:revert"></ul></li><li><a href="/categories/computer-science/">Computer Science (104)</a><ul style="padding:revert"><li><a href="/categories/computer-science/architecture-design/">Architecture Design (7)</a><ul style="padding:revert"></ul></li><li><a href="/categories/computer-science/cloud/">Cloud (1)</a><ul style="padding:revert"></ul></li><li><a href="/categories/computer-science/Engineering/">Engineering (1)</a><ul style="padding:revert"></ul></li><li><a href="/categories/computer-science/gradle/">Gradle (4)</a><ul style="padding:revert"></ul></li><li><a href="/categories/computer-science/graphics/">Graphics (2)</a><ul style="padding:revert"></ul></li><li><a href="/categories/computer-science/java/">Java (12)</a><ul style="padding:revert"></ul></li><li><a href="/categories/computer-science/kotlin/">Kotlin (7)</a><ul style="padding:revert"></ul></li><li><a href="/categories/computer-science/mobile/">Mobile (10)</a><ul style="padding:revert"><li><a href="/categories/computer-science/mobile/android/">Android (5)</a></li><li><a href="/categories/computer-science/mobile/flutter/">Flutter (1)</a></li></ul></li><li><a href="/categories/computer-science/observability/">Observability (2)</a><ul style="padding:revert"></ul></li><li><a href="/categories/computer-science/open-source/">Open Source (56)</a><ul style="padding:revert"><li><a href="/categories/computer-science/open-source/booster/">Booster (56)</a></li></ul></li><li><a href="/categories/computer-science/Programming/">Programming (2)</a><ul style="padding:revert"></ul></li></ul></li><li><a href="/categories/diy/">DIY (1)</a><ul style="padding:revert"></ul></li><li><a href="/categories/Independent-Thinking/">Independent Thinking (27)</a><ul style="padding:revert"></ul></li><li><a href="/categories/Investing/">Investing (3)</a><ul style="padding:revert"></ul></li><li><a href="/categories/Investment/">Investment (1)</a><ul style="padding:revert"></ul></li><li><a href="/categories/life/">Life (9)</a><ul style="padding:revert"></ul></li><li><a href="/categories/reading/">Reading (2)</a><ul style="padding:revert"></ul></li><li><a href="/categories/UI-UX/">UI/UX (1)</a><ul style="padding:revert"><li><a href="/categories/UI-UX/Design-System/">Design System (1)</a><ul style="padding:revert"></ul></li></ul></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/JVM/" style="font-size: 15px;">JVM</a> <a href="/tags/Korea/" style="font-size: 15px;">Korea</a> <a href="/tags/Seoul/" style="font-size: 15px;">Seoul</a> <a href="/tags/Independent-Thinking/" style="font-size: 15px;">Independent Thinking</a> <a href="/tags/Gradle/" style="font-size: 15px;">Gradle</a> <a href="/tags/java-gradle-plugin/" style="font-size: 15px;">java-gradle-plugin</a> <a href="/tags/AI/" style="font-size: 15px;">AI</a> <a href="/tags/Agent/" style="font-size: 15px;">Agent</a> <a href="/tags/Claude/" style="font-size: 15px;">Claude</a> <a href="/tags/Career/" style="font-size: 15px;">Career</a> <a href="/tags/Browser-Automation/" style="font-size: 15px;">Browser Automation</a> <a href="/tags/Puppeteer/" style="font-size: 15px;">Puppeteer</a> <a href="/tags/CDP/" style="font-size: 15px;">CDP</a> <a href="/tags/DOM/" style="font-size: 15px;">DOM</a> <a href="/tags/Web-Scraping/" style="font-size: 15px;">Web Scraping</a> <a href="/tags/Self-Reflection/" style="font-size: 15px;">Self-Reflection</a> <a href="/tags/LLM/" style="font-size: 15px;">LLM</a> <a href="/tags/Gemini/" style="font-size: 15px;">Gemini</a> <a href="/tags/Alignment/" style="font-size: 15px;">Alignment</a> <a href="/tags/Communication/" style="font-size: 15px;">Communication</a> <a href="/tags/Investing/" style="font-size: 15px;">Investing</a> <a href="/tags/ROI/" style="font-size: 15px;">ROI</a> <a href="/tags/Big-Tech/" style="font-size: 15px;">Big Tech</a> <a href="/tags/Infrastructure/" style="font-size: 15px;">Infrastructure</a> <a href="/tags/Blog/" style="font-size: 15px;">Blog</a> <a href="/tags/Productivity/" style="font-size: 15px;">Productivity</a> <a href="/tags/Workflow/" style="font-size: 15px;">Workflow</a> <a href="/tags/Android/" style="font-size: 15px;">Android</a> <a href="/tags/Build/" style="font-size: 15px;">Build</a> <a href="/tags/Compiler/" style="font-size: 15px;">Compiler</a> <a href="/tags/iOS/" style="font-size: 15px;">iOS</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/Kotlin/" style="font-size: 15px;">Kotlin</a> <a href="/tags/ES5/" style="font-size: 15px;">ES5</a> <a href="/tags/ES6/" style="font-size: 15px;">ES6</a> <a href="/tags/JavaScript/" style="font-size: 15px;">JavaScript</a> <a href="/tags/Booster/" style="font-size: 15px;">Booster</a> <a href="/tags/Performance-Optimization/" style="font-size: 15px;">Performance Optimization</a> <a href="/tags/ReleaseNote/" style="font-size: 15px;">ReleaseNote</a> <a href="/tags/Stock/" style="font-size: 15px;">Stock</a> <a href="/tags/ChatGPT/" style="font-size: 15px;">ChatGPT</a> <a href="/tags/Financial-Analysis/" style="font-size: 15px;">Financial Analysis</a> <a href="/tags/Model-Evaluation/" style="font-size: 15px;">Model Evaluation</a> <a href="/tags/UX/" style="font-size: 15px;">UX</a> <a href="/tags/Compatibility/" style="font-size: 15px;">Compatibility</a> <a href="/tags/Lambda/" style="font-size: 15px;">Lambda</a> <a href="/tags/Education/" style="font-size: 15px;">Education</a> <a href="/tags/Software-Engineering/" style="font-size: 15px;">Software Engineering</a> <a href="/tags/Architecture/" style="font-size: 15px;">Architecture</a> <a href="/tags/AGP/" style="font-size: 15px;">AGP</a> <a href="/tags/Dart/" style="font-size: 15px;">Dart</a> <a href="/tags/Flutter/" style="font-size: 15px;">Flutter</a> <a href="/tags/Maven/" style="font-size: 15px;">Maven</a> <a href="/tags/Coupang/" style="font-size: 15px;">Coupang</a> <a href="/tags/Reveal2021/" style="font-size: 15px;">Reveal2021</a> <a href="/tags/Music/" style="font-size: 15px;">Music</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Transformer/" style="font-size: 15px;">Transformer</a> <a href="/tags/Deep-Learning/" style="font-size: 15px;">Deep Learning</a> <a href="/tags/HTML/" style="font-size: 15px;">HTML</a> <a href="/tags/Programming/" style="font-size: 15px;">Programming</a> <a href="/tags/Economics/" style="font-size: 15px;">Economics</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/SPI/" style="font-size: 15px;">SPI</a> <a href="/tags/MVVM/" style="font-size: 15px;">MVVM</a> <a href="/tags/JetPack/" style="font-size: 15px;">JetPack</a> <a href="/tags/Preloading/" style="font-size: 15px;">Preloading</a> <a href="/tags/Mental-Health/" style="font-size: 15px;">Mental Health</a> <a href="/tags/Finance/" style="font-size: 15px;">Finance</a> <a href="/tags/Society/" style="font-size: 15px;">Society</a> <a href="/tags/Wall-Street/" style="font-size: 15px;">Wall Street</a> <a href="/tags/Contrarian/" style="font-size: 15px;">Contrarian</a> <a href="/tags/Alpha/" style="font-size: 15px;">Alpha</a> <a href="/tags/Risk-Management/" style="font-size: 15px;">Risk Management</a> <a href="/tags/Hiring/" style="font-size: 15px;">Hiring</a> <a href="/tags/Interview/" style="font-size: 15px;">Interview</a> <a href="/tags/Engineering-Leadership/" style="font-size: 15px;">Engineering Leadership</a> <a href="/tags/Housing/" style="font-size: 15px;">Housing</a> <a href="/tags/Evolution/" style="font-size: 15px;">Evolution</a> <a href="/tags/DeepMind/" style="font-size: 15px;">DeepMind</a> <a href="/tags/AlphaFold2/" style="font-size: 15px;">AlphaFold2</a> <a href="/tags/CASP/" style="font-size: 15px;">CASP</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2026/02/26/from-llm-to-effective-communication/">从 LLM 到高效沟通</a></li><li class="post-list-item"><a class="post-list-link" href="/2026/02/25/from-compiler-to-llm/">从编译器到 LLM：软件分层的轮回</a></li><li class="post-list-item"><a class="post-list-link" href="/2026/02/25/llm-is-a-function/">LLM 的本质——函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2026/02/25/tetris-effect-of-ai-conversations/">植入潜意识——AI 版的盗梦空间</a></li><li class="post-list-item"><a class="post-list-link" href="/2026/02/15/ai-as-thinking-partner/">当 AI 成为你的“思考伙伴”</a></li><li class="post-list-item"><a class="post-list-link" href="/2026/02/14/agora-technical-journey/">Agora 的技术选型与踩坑实录</a></li><li class="post-list-item"><a class="post-list-link" href="/2026/02/13/confirmation-bias/">别让你的认知偏差限制了 AI 的发挥</a></li><li class="post-list-item"><a class="post-list-link" href="/2026/02/12/what-should-engineering-hiring-evaluate-in-ai-era/">都 2026 了，还在考算法？</a></li><li class="post-list-item"><a class="post-list-link" href="/2026/02/12/ai-debate-what-i-learned/">一场 AI 辩论暴露了 LLM 性格的本质</a></li><li class="post-list-item"><a class="post-list-link" href="/2026/02/11/ai-investment-roi-reality-check/">一年烧 $700B，谁会是下一个摩托罗拉？</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/johnsonlee" title="GitHub" target="_blank">GitHub</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2026 <a href="/." rel="nofollow">Johnson Lee.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-154930895-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.async = 1;
  hm.src = 'https://hm.baidu.com/hm.js?' + 'bceb83a2d24731111cbcf93ac3960952';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script><script>load('/libs/viz/2.1.2/viz.js').then(() => {
  let graphs = document.querySelectorAll('.graphviz')

  if (graphs.length > 0) {
    for (let graph of graphs) {
      let svg = undefined;
      try {
        svg = Viz(graph.textContent.replaceAll('–', '--'), 'svg');
      } catch(e) {
        svg = `<pre class="error">${e}</pre>`;
      }
      graph.outerHTML = svg;
    }
  }
});
</script><script>load('/libs/jquery/3.4.0/jquery.min.js').then(() => {
  load(
    '/js/search.js',
    '/js/share.js',
    '/js/smartresize.js',
    '/js/totop.js'
  ).then(() => {
    load('/js/codeblock-resizer.js').then(() => {});
    ('function' == typeof setupSearch) && setupSearch();
  });
});</script></div></body></html>